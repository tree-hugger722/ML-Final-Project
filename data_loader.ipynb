{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43f4a8ca",
   "metadata": {},
   "source": [
    "Loads in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "484eadb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c44bd6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_energy_data():\n",
    "    '''\n",
    "    Loads each of the 4 data sets (3 sets of meter readings and one meta data \n",
    "    set) in as dataframes\n",
    "    \n",
    "    '''\n",
    "    # read in data from meter readings\n",
    "    source_dir = \"building_genome_datasets/\"\n",
    "    file_suffix = \"_cleaned.csv\"\n",
    "    meters = [\"electricity\",\"gas\",\"solar\"]\n",
    "    electricity_data = pd.read_csv(source_dir+\"electricity\"+file_suffix)\n",
    "    gas_data = pd.read_csv(source_dir+\"gas\"+file_suffix)\n",
    "    solar_data = pd.read_csv(source_dir+\"solar\"+file_suffix)\n",
    "    metadata = pd.read_csv(source_dir+\"metadata.csv\")\n",
    "    metadata = metadata.drop([\"site_id\", \"building_id_kaggle\", \"site_id_kaggle\", \"eui\", \"heatingtype\", \"source_eui\", \"site_eui\", \"energystarscore\", \"leed_level\", \"rating\", \"date_opened\", \"electricity\", \"hotwater\", \"chilledwater\", \"solar\", \"gas\", \"steam\", \"water\", \"irrigation\", \"industry\", \"subindustry\"], axis=1)\n",
    "    median_energy_usage = pd.read_csv(\"CS374-Final-Project/median_energy_usage.csv\")\n",
    "\n",
    "    return electricity_data, gas_data, solar_data, metadata, median_energy_usage, meters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f251c89c",
   "metadata": {},
   "source": [
    "Source EUI calculation functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5abbf40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_source_eui(area, total_energy):\n",
    "    \"\"\"\n",
    "    Given an int total_energy in kWh and an int area representing total building surface area,\n",
    "    returns the source energy use intensity\n",
    "    \"\"\"\n",
    "    return total_energy/area\n",
    "\n",
    "def calculate_total_energy(electricity, gas, solar):\n",
    "    \"\"\"\n",
    "    Given electricity, natural gas, and solar meter reading in kWh returns the total energy \n",
    "    usage (weighted according to the American Insistute of Architects:\n",
    "    https://aiacalifornia.org/energy-use-intensity-eui/)\n",
    "    \"\"\"\n",
    "    return (electricity*2.8)+(gas*1.05)+solar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dc9cc2",
   "metadata": {},
   "source": [
    "Helper functions for adding categorical variables and generating the outcome variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cd75e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_categorical(data, category):\n",
    "    \"\"\"\n",
    "    Given a dataframe data and string category, returns a dataframe with \n",
    "    category converted into categorical variables with 1/0 encoding\n",
    "    \"\"\"\n",
    "    data_copy = data.copy()\n",
    "    data_copy = pd.get_dummies(data_copy, prefix= [category], columns=[category])\n",
    "    return data_copy\n",
    "\n",
    "def add_eui_and_outcome(electricity, gas, solar, data, median_energy_usage):\n",
    "    \"\"\"\n",
    "    Given the aggregate dataset, electricity, gas, and solar meter data sets and\n",
    "    the reference data set of national median energy use intensity for each\n",
    "    type of building, calculates the source's eui, adds it to the aggregate \n",
    "    dataset and adds a binary outcome that is 1 if the source eui is < the\n",
    "    national median and 0 otherwise.\n",
    "    \"\"\"\n",
    "    data_copy = data.copy()\n",
    "    source_euis = []\n",
    "    isEfficent = []\n",
    "\n",
    "    electricity_start = electricity.index[electricity['timestamp'] == \"2017-01-01 00:00:00\"].tolist()\n",
    "    electricity_end = electricity.index[electricity['timestamp'] == \"2017-12-31 23:00:00\"].tolist()\n",
    "    gas_start = gas.index[gas['timestamp'] == \"2017-01-01 00:00:00\"].tolist()\n",
    "    gas_end = gas.index[gas['timestamp'] == \"2017-12-31 23:00:00\"].tolist()\n",
    "    solar_start = solar.index[solar['timestamp'] == \"2017-01-01 00:00:00\"].tolist()\n",
    "    solar_end = solar.index[solar['timestamp'] == \"2017-12-31 23:00:00\"].tolist()\n",
    "\n",
    "    for row in range(len(data)):\n",
    "        # get the building id\n",
    "        building_id = data_copy['building_id'].iloc[row]\n",
    "\n",
    "        # sum electricity usage for this building in 2017\n",
    "        electricity_total = 0\n",
    "        gas_total = 0\n",
    "        solar_total = 0\n",
    "\n",
    "        # check if building is in the electricity meter set\n",
    "        if building_id in electricity.columns.tolist():\n",
    "            new_electricity = electricity.copy()           \n",
    "            electricity_total_building = new_electricity.get(building_id)\n",
    "            electricity_total = (electricity_total_building.iloc[electricity_start[0]:electricity_end[0]]).sum()\n",
    "        if building_id in gas.columns.tolist():\n",
    "            new_gas = gas.copy()\n",
    "            gas_total_building = new_gas.get(building_id)\n",
    "            gas_total = (gas_total_building.iloc[gas_start[0]:gas_end[0]]).sum()\n",
    "        if building_id in solar.columns.tolist():\n",
    "            new_solar = solar.copy()\n",
    "            solar_total_building = new_solar.get(building_id)\n",
    "            solar_total = (solar_total_building.iloc[solar_start[0]:solar_end[0]]).sum()\n",
    "\n",
    "        total_energy = calculate_total_energy(electricity_total, gas_total, solar_total)\n",
    "        source_eui = calculate_source_eui(data_copy['sqft'].iloc[row], total_energy)\n",
    "        source_euis.append(source_eui)\n",
    "\n",
    "        comparison_val = get_median_energy_val(median_energy_usage, get_primary_cat(data_copy, row), get_sub_cat(data_copy,row))\n",
    "        \n",
    "        if comparison_val > source_eui:\n",
    "            isEfficent.append(1)\n",
    "        else:\n",
    "            isEfficent.append(0)\n",
    "\n",
    "    data_copy[\"source_eui_est\"] = source_euis\n",
    "    data_copy[\"isEfficient\"] = isEfficent\n",
    "\n",
    "    return data_copy\n",
    "\n",
    "def get_primary_cat(data, row):\n",
    "    \"\"\"\n",
    "    Retrieves the string primaryspaceusage of the building in a given row of data\n",
    "    \"\"\"\n",
    "    new_df = data.copy()\n",
    "    new_df = new_df.filter(regex=\"^primaryspaceusage\",axis=1)\n",
    "    for col in new_df.columns.tolist():\n",
    "        if new_df.get(col).iloc[row] == 1:\n",
    "            return col\n",
    "    return \"other\"\n",
    "\n",
    "def get_sub_cat(data, row):\n",
    "    \"\"\"\n",
    "    Retrieves the string sub_primaryspaceusage of the building in a given row of data\n",
    "    \"\"\"\n",
    "    new_df = data.copy()\n",
    "    new_df = new_df.filter(regex=\"^sub_primaryspaceusage\",axis=1)\n",
    "    for col in new_df.columns.tolist():\n",
    "        if new_df.get(col).iloc[row] == 1:\n",
    "            return col\n",
    "    return \"other\"\n",
    "\n",
    "def get_median_energy_val(median_energy_usage, primary_cat, sub_cat):\n",
    "    \"\"\"\n",
    "    Given the reference set of median energy use intensity by building category,\n",
    "    the primary and sub usage categories, returns the corresponding median\n",
    "    source eui. \n",
    "    \"\"\"\n",
    "    primary_cat = primary_cat.split(\"_\")[-1].lower()\n",
    "    sub_cat = sub_cat.split(\"_\")[-1].lower()\n",
    "    broad_cat_indices = median_energy_usage.index[median_energy_usage['Broad Category'] == primary_cat].tolist()\n",
    "    broad_cat_df = median_energy_usage.iloc[broad_cat_indices]\n",
    "\n",
    "    \n",
    "    # iterate through broad_cat_df and check if name of the sub_cat is the same as either the Primary Function \n",
    "    # or the Further Breakdown categories\n",
    "    for row in range(len(broad_cat_df)):\n",
    "\n",
    "        if broad_cat_df['Primary Function'].iloc[row] == sub_cat:\n",
    "            return broad_cat_df[\"Source EUI\"].iloc[row]\n",
    "\n",
    "        if broad_cat_df['Further Breakdown'].iloc[row] != \"\":\n",
    "            if sub_cat == broad_cat_df['Further Breakdown'].iloc[row]:\n",
    "                return broad_cat_df['Source EUI'].iloc[row]\n",
    "\n",
    "    # find the corresponding 'Other' Category (this is simplified for now, \n",
    "    # improve this to check the 'Further Breakdown' for the future)\n",
    "    for row in range(len(broad_cat_df)):\n",
    "        if (sub_cat in broad_cat_df['Primary Function'].iloc[row]) or (\"other\" in broad_cat_df['Primary Function'].iloc[row]):\n",
    "            return broad_cat_df[\"Source EUI\"].iloc[row]   \n",
    "    return 89.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe08a90",
   "metadata": {},
   "source": [
    "Helper functions for adding processed meter readings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0fb5e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_daily_totals(start, end, data):\n",
    "    \"\"\"\n",
    "    Given some dataframe containing meter readings, a start and an end timestamp,\n",
    "    returns a dataframe with a single row containing the sum of all the readings\n",
    "    in that timeframe\n",
    "    \"\"\"\n",
    "    data_copy = data.copy()\n",
    "    start_index = data_copy.index[data_copy['timestamp'] == start].tolist()\n",
    "    end_index = data_copy.index[data_copy['timestamp'] == end].tolist()\n",
    "    column_sum = data_copy.iloc[start_index[0]:end_index[0]].sum().to_frame().T\n",
    "\n",
    "    return column_sum\n",
    "\n",
    "def avg_daily_totals(daily_totals, month, meter_type):\n",
    "    \"\"\"\n",
    "    Given a list of dataframes containing singular rows with total daily resource usage (each \n",
    "    dataframe in the list holds totals from a particular day in the week), the number of buildings in the\n",
    "    dataset, the string month and string meter type, returns a single dataframe containing\n",
    "    the average daily resource usage over the week\n",
    "    \"\"\"\n",
    "\n",
    "    data = daily_totals[0].copy()\n",
    "    data = data.iloc[:,1:len(data.columns.tolist())]\n",
    "    for day in range(1,len(daily_totals)):\n",
    "        adjusted_daily_total_frame = daily_totals[day].copy().iloc[:,1:len(daily_totals[day].columns.tolist())]\n",
    "        data = data.combine(adjusted_daily_total_frame, lambda x,y: x+y, fill_value=0)\n",
    "\n",
    "    daily_avg_over_week = data.apply(lambda x: x/7, raw=True, axis=1)\n",
    "\n",
    "    daily_avg_over_week = daily_avg_over_week.transpose().reset_index().rename(columns={'index':'building_id'})\n",
    "    daily_avg_over_week.rename(columns={0:(meter_type+\"_\"+month)}, inplace=True)\n",
    "\n",
    "    return daily_avg_over_week\n",
    "\n",
    "def avg_meter_readings(meter_set, meter_type, month):\n",
    "    \"\"\"\n",
    "    Given a dataset for a particular meter's readings, the number of buildings\n",
    "    in the data set, and the month of readings to be analyzed, returns a dataframe\n",
    "    of daily averages for a week in that month.\n",
    "    \"\"\"\n",
    "    \n",
    "    if month == \"jan\":\n",
    "        mon = \"01\"\n",
    "    elif month == \"april\":\n",
    "        mon = \"04\"\n",
    "    elif month == \"july\":\n",
    "        mon = \"07\"\n",
    "    elif month == \"oct\":\n",
    "        mon = \"10\"\n",
    "    else:\n",
    "        raise Exception(\"Invalid month\")\n",
    "\n",
    "    date_bounds = [(\"2016-\"+mon+\"-01 00:00:00\", \"2016-\"+mon+\"-02 00:00:00\"),(\"2016-\"+mon+\"-02 00:00:00\", \"2016-\"+mon+\"-03 00:00:00\"),(\"2016-\"+mon+\"-03 00:00:00\", \"2016-\"+mon+\"-04 00:00:00\"),(\"2016-\"+mon+\"-04 00:00:00\", \"2016-\"+mon+\"-05 00:00:00\"),(\"2016-\"+mon+\"-05 00:00:00\", \"2016-\"+mon+\"-06 00:00:00\"),(\"2016-\"+mon+\"-06 00:00:00\", \"2016-\"+mon+\"-07 00:00:00\"),(\"2016-\"+mon+\"-07 00:00:00\", \"2016-\"+mon+\"-08 00:00:00\")]\n",
    "    daily_totals = [find_daily_totals(start,end,meter_set) for (start,end) in date_bounds]\n",
    "\n",
    "    # now average each of the values from the sets and output a new dataframe with readings from each building\n",
    "    return avg_daily_totals(daily_totals, month, meter_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109b0f92",
   "metadata": {},
   "source": [
    "Top-level function to clean the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d6ec679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(meters, meter_sets, metadata, median_energy_usage, months):\n",
    "    \"\"\"\n",
    "    Calculates the average energy use over a week in \n",
    "    each season for each meter, calculates the source eui for 2017 of each\n",
    "    building, converts categorical columns into dummy variables, creates a \n",
    "    binary outcome variable (1 if building's 2017 source eui is above the \n",
    "    national median, 0 otherwise) and returns the aggregated dataset.\n",
    "    \"\"\"\n",
    "    # create 32 new features: one daily average reading over a week per season, per meter type\n",
    "    for meter_type in range(len(meters)):\n",
    "        for month in months:\n",
    "            new_feature = avg_meter_readings(meter_sets[meter_type], meters[meter_type], month)\n",
    "\n",
    "            # join in a way that aligns the building_id\n",
    "            metadata = pd.merge(metadata, new_feature, on=\"building_id\", how=\"left\")\n",
    "     \n",
    "    metadata = convert_categorical(metadata, \"primaryspaceusage\")\n",
    "    metadata = convert_categorical(metadata, \"sub_primaryspaceusage\")\n",
    "    metadata = convert_categorical(metadata, \"timezone\")\n",
    "\n",
    "    metadata = add_eui_and_outcome(meter_sets[meters.index(\"electricity\")], meter_sets[meters.index(\"gas\")], meter_sets[meters.index(\"solar\")], metadata, median_energy_usage)\n",
    "    metadata.to_csv(\"building_genome_datasets/final3_cleaned.csv\")\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206f831d",
   "metadata": {},
   "source": [
    "Generate the final data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad691e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final data set in final_data\n",
    "electricity_data, gas_data, solar_data, metadata, median_energy_usage, meters = load_energy_data()\n",
    "months = [\"jan\", \"april\", \"july\", \"oct\"]\n",
    "meter_sets = [electricity_data, gas_data, solar_data]\n",
    "final_data = clean_data(meters, meter_sets, metadata, median_energy_usage, months)\n",
    "print( \"final data set: \\n\", final_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ac7571",
   "metadata": {},
   "source": [
    "Linear Logistic Regression Implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73cb6cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_negative_loglikelihood(Y, pYhat):\n",
    "    \"\"\"\n",
    "    Function for computing the mean negative loglikelihood.\n",
    "    \n",
    "    Y is a vector of the true 0/1 labels.\n",
    "    pYhat is a vector of estimated probabilities, where each entry i is p(Y_i=1 | ... )\n",
    "    \"\"\"\n",
    "    # weigh 0 labels 2x as much as 1 labels\n",
    "    weights = []\n",
    "    for outcome in Y:\n",
    "        if outcome == 0:\n",
    "            weights.append(2)\n",
    "        else:\n",
    "            weights.append(1)\n",
    "    \n",
    "    neg_loglikelihood = (Y*np.log(pYhat))+((1-Y)*np.log(1-pYhat))\n",
    "    weighted_nll = np.multiply(weights, neg_loglikelihood)\n",
    "    mean = np.mean(weighted_nll)\n",
    "\n",
    "    return -mean\n",
    "\n",
    "\n",
    "def accuracy(Y, Yhat):\n",
    "    \"\"\"\n",
    "    Function for computing accuracy.\n",
    "    \n",
    "    Y is a vector of the true labels and Yhat is a vector of estimated 0/1 labels\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.sum(Y==Yhat)/len(Y)\n",
    "    \n",
    "def sigmoid(V):\n",
    "    \"\"\"\n",
    "    Function for mapping a vector of floats to probabilities via the sigmoid function\n",
    "    \"\"\"\n",
    "    \n",
    "    return 1/(1+np.exp(-V))\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    \n",
    "    def __init__(self, learning_rate=0.1, lamda=None):\n",
    "        \"\"\"\n",
    "        Constructor for the class. Learning rate is\n",
    "        any positive number controlling step size of gradient descent.\n",
    "        Lamda is a positive number controlling the strength of regularization.\n",
    "        When None, no penalty is added.\n",
    "        \"\"\"\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lamda = lamda\n",
    "        self.theta = None # theta is initialized once we fit the model\n",
    "    \n",
    "    def _calculate_gradient(self, Xmat, Y, theta_p, h=1e-5):\n",
    "        \"\"\"\n",
    "        Helper function for computing the gradient at a point theta_p.\n",
    "        \"\"\"\n",
    "        l2_regularization = (self.lamda * (np.sum(theta_p**2))) if self.lamda else 0\n",
    "        \n",
    "        # initialize an empty gradient vector\n",
    "        n, d = Xmat.shape\n",
    "\n",
    "        grad_vec = np.zeros(d)\n",
    "        outcome_no_perturb = mean_negative_loglikelihood(Y, sigmoid(np.dot(Xmat,np.transpose(theta_p)))) + l2_regularization\n",
    "\n",
    "        # Take the partial derivative with respect to each feature and update\n",
    "        # the gradient vector\n",
    "        for i in range(len(grad_vec)):\n",
    "            theta_new = theta_p.copy()\n",
    "            theta_new[i] += h\n",
    "            l2_regularization = (self.lamda * (np.sum(theta_new**2))) if self.lamda else 0\n",
    "            outcome_perturb = mean_negative_loglikelihood(Y, sigmoid(np.dot(Xmat,np.transpose(theta_new)))) + l2_regularization\n",
    "            grad_vec[i] = (outcome_perturb - outcome_no_perturb)/h\n",
    "\n",
    "        return grad_vec\n",
    "\n",
    "    def fit(self, Xmat, Y, max_iterations=1000, tolerance=1e-6, verbose=False):\n",
    "        \"\"\"\n",
    "        Fit a logistic regression model using training data Xmat and Y.\n",
    "        \"\"\"\n",
    "        # add a column of ones for the intercept\n",
    "        n, d = Xmat.shape        \n",
    "        \n",
    "        # initialize theta and theta new randomly\n",
    "        theta = np.random.uniform(-1, 1, d)\n",
    "        theta_new = np.random.uniform(-1, 1, d)\n",
    "        iteration = 0\n",
    "\n",
    "        # keep going until convergence\n",
    "        while iteration < max_iterations and np.mean(np.abs(theta_new-theta)) >= tolerance:\n",
    "            \n",
    "            if verbose:\n",
    "                print(\"Iteration\", iteration, \"theta=\", theta)\n",
    "\n",
    "            # gradient descent\n",
    "            theta_new_og = theta_new.copy()\n",
    "            grad_vec = self._calculate_gradient(Xmat, Y, theta)\n",
    "            theta_new = theta - self.learning_rate*grad_vec\n",
    "            iteration += 1\n",
    "            theta = theta_new_og.copy()\n",
    "            \n",
    "        self.theta = theta_new.copy()\n",
    "        \n",
    "    def predict(self, Xmat):\n",
    "        \"\"\"\n",
    "        Predict 0/1 labels for a data matrix Xmat based on the following rule:\n",
    "        if p(Y=1|X) > 0.5 output a label of 1, else output a label of 0\n",
    "        \"\"\"\n",
    "        # vector of predicated values\n",
    "        pYhat = sigmoid(np.dot(Xmat,np.transpose(self.theta)))\n",
    "        \n",
    "        # fill output vector with binary 1/0 labels\n",
    "        output = []\n",
    "        for row in range(len(Xmat)):\n",
    "            if pYhat[row] > 0.5:\n",
    "                output.append(1) \n",
    "            else:\n",
    "                output.append(0)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e78b5",
   "metadata": {},
   "source": [
    "Split the data into training, testing, and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8e258725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data():\n",
    "    '''\n",
    "    Process borrowed from HW4, reads in data from a csv, cleans it, standardizes it, and fits a model \n",
    "    '''\n",
    "    np.random.seed(333)\n",
    "    data_clean = final_data.drop(columns=[\"building_id\",\"source_eui_est\"])\n",
    "    data_clean = data_clean.fillna(0)\n",
    "    feature_names = data_clean.drop(columns=[\"isEfficient\"]).columns.tolist()\n",
    "\n",
    "    \n",
    "    # Dataset for the ablation study -- omits energy meter data\n",
    "    data_ablation = data_clean.copy().drop(columns=[\"electricity_jan\",\"electricity_april\",\"electricity_july\",\"electricity_oct\",\"gas_jan\",\"gas_april\",\"gas_july\",\"gas_oct\",\"solar_jan\",\"solar_april\",\"solar_july\", \"solar_oct\"])\n",
    "    feature_names_ablation = data_ablation.drop(columns=[\"isEfficient\"]).columns.tolist()\n",
    "    \n",
    "    ##############################################################\n",
    "    ### FULL DATA SET  ###\n",
    "    Dmat = data_clean.drop(columns=[\"isEfficient\"]).to_numpy()\n",
    "    Y = data_clean[\"isEfficient\"].to_numpy()\n",
    "    \n",
    "    # standardize the data and add column of 1's for intercept (taken from hw1)\n",
    "    Dcont = Dmat[:, 0:18]\n",
    "    mean = Dcont.mean(axis=0)\n",
    "    std = Dcont.std(axis=0)\n",
    "    Dcont = (Dcont - mean)/std\n",
    "    Xmat = np.column_stack((np.ones(len(Dmat)),Dcont[:,0:18], Dmat[:,19:]))\n",
    "    feature_names = [\"intercept\"] + feature_names\n",
    "    \n",
    "    # split data\n",
    "    Xmat_train, Xmat_test, Y_train, Y_test = train_test_split(Xmat, Y, test_size=0.33, random_state=42)\n",
    "    Xmat_train, Xmat_val, Y_train, Y_val = train_test_split(Xmat_train, Y_train, test_size=0.33, random_state=42)\n",
    "    n, d = Xmat_train.shape\n",
    "    \n",
    "    full_data = {\"Xmat_train\": Xmat_train, \"Xmat_val\": Xmat_val, \"Xmat_test\": Xmat_test,\n",
    "            \"Y_train\": Y_train, \"Y_val\": Y_val, \"Y_test\": Y_test}\n",
    "    \n",
    "    ##################################################################\n",
    "    ### ABLATION DATA SET ###\n",
    "    Dmat_ab = data_ablation.drop(columns=[\"isEfficient\"]).to_numpy()\n",
    "    Y_ab = data_ablation[\"isEfficient\"].to_numpy()\n",
    "    \n",
    "    # standardize the data and add column of 1's for intercept (taken from hw1)\n",
    "    Dcont_ab = Dmat_ab[:, 0:18]\n",
    "    mean_ab = Dcont_ab.mean(axis=0)\n",
    "    std_ab = Dcont_ab.std(axis=0)\n",
    "    Dcont_ab = (Dcont_ab - mean)/std\n",
    "    Xmat_ab = np.column_stack((np.ones(len(Dmat_ab)),Dcont_ab[:,0:18], Dmat_ab[:,19:]))\n",
    "    feature_names_ablation = [\"intercept\"] + feature_names_ablation\n",
    "    \n",
    "    # split data\n",
    "    Xmat_train_ab, Xmat_test_ab, Y_train_ab, Y_test_ab = train_test_split(Xmat_ab, Y_ab, test_size=0.33, random_state=42)\n",
    "    Xmat_train_ab, Xmat_val_ab, Y_train_ab, Y_val_ab = train_test_split(Xmat_train_ab, Y_train_ab, test_size=0.33, random_state=42)\n",
    "    n, d = Xmat_train_ab.shape\n",
    "    \n",
    "    ablation_data = {\"Xmat_train\": Xmat_train_ab, \"Xmat_val\": Xmat_val_ab, \"Xmat_test\": Xmat_test_ab,\n",
    "            \"Y_train\": Y_train_ab, \"Y_val\": Y_val_ab, \"Y_test\": Y_test_ab}\n",
    "    \n",
    "    \n",
    "    return feature_names, feature_names_ablation, full_data, ablation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65bfb07",
   "metadata": {},
   "source": [
    "Run logistic linear regression and neural net: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7886a472",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names, feature_names_ablation, data, ablation_data = split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a054c39",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_logistic_model():\n",
    "    \"\"\"\n",
    "    Fits logistic linear regression on an aggregated and cleaned building genome dataset\n",
    "    Prints accuracy results\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Logistic Regression ###\n",
    "    model_base = LogisticRegression(learning_rate=0.2, lamda=0.0)\n",
    "    model_base.fit(data[\"Xmat_train\"], data[\"Y_train\"])\n",
    "\n",
    "    Yhat_test_naive = np.ones((data[\"Y_test\"].shape), dtype=int)\n",
    "    val_size = data[\"Y_val\"].shape\n",
    "    train_size = data[\"Y_train\"].shape\n",
    "    Yhat_val_naive = np.ones(val_size, dtype=int)\n",
    "    Yhat_train_naive = np.ones(train_size, dtype=int)\n",
    "    \n",
    "    Yhat_train_base = model_base.predict(data[\"Xmat_train\"])\n",
    "    Yhat_val_base = model_base.predict(data[\"Xmat_val\"])\n",
    "\n",
    "    ### ACCURACY ###\n",
    "    accuracy_naive = accuracy(data[\"Y_val\"], Yhat_val_naive)\n",
    "    accuracy_base = accuracy(data[\"Y_val\"], Yhat_val_base)\n",
    "    accuracy_train_naive = accuracy(data[\"Y_train\"], Yhat_train_naive)\n",
    "    accuracy_train_base = accuracy(data[\"Y_train\"], Yhat_train_base)\n",
    "\n",
    "    print(\"\\nResults:\\n\" + \"-\"*4)\n",
    "    print(\"Training accuracy naive\", accuracy_train_naive)\n",
    "    print(\"Training accuracy no regularization\", accuracy_train_base)\n",
    "    print(\"Validation accuracy naive\", accuracy_naive)\n",
    "    print(\"Validation accuracy no regularization\", accuracy_base)    \n",
    "    \n",
    "    ## PRECISION, RECALL, F1 ##\n",
    "    precision_naive = precision_score(Yhat_val_naive, data[\"Y_val\"])\n",
    "    recall_naive = recall_score(Yhat_val_naive, data[\"Y_val\"])\n",
    "    f1_naive = f1_score(Yhat_val_naive, data[\"Y_val\"])\n",
    "    \n",
    "    precision_naive_train = precision_score(Yhat_train_naive, data[\"Y_train\"])\n",
    "    recall_naive_train = recall_score(Yhat_train_naive, data[\"Y_train\"])\n",
    "    f1_naive_train = f1_score(Yhat_train_naive, data[\"Y_train\"])\n",
    "    \n",
    "    precision_base = precision_score(Yhat_val_base, data[\"Y_val\"])\n",
    "    recall_base = recall_score(Yhat_val_base, data[\"Y_val\"])\n",
    "    f1_base = f1_score(Yhat_val_base, data[\"Y_val\"])\n",
    "    \n",
    "    precision_base_train = precision_score(Yhat_train_base, data[\"Y_train\"])\n",
    "    recall_base_train = recall_score(Yhat_train_base, data[\"Y_train\"])\n",
    "    f1_base_train = f1_score(Yhat_train_base, data[\"Y_train\"])\n",
    "        \n",
    "    print(\"Naive training precision : \", precision_naive_train, \" recall: \", recall_naive_train, \" F1 score: \", f1_naive_train)\n",
    "    print(\"Base training precision : \", precision_base_train, \" recall: \", recall_base_train, \" F1 score: \", f1_base_train)\n",
    "    print(\"Naive validation precision : \", precision_naive, \" recall: \", recall_naive, \" F1 score: \", f1_naive)\n",
    "    print(\"Base validation precision : \", precision_base, \" recall: \", recall_base, \" F1 score: \", f1_base)\n",
    "\n",
    "    # choose best model\n",
    "    best_model = model_base\n",
    "    Yhat_test = best_model.predict(data[\"Xmat_test\"])\n",
    "    print(\"Logistic Regression Test accuracy\", accuracy(data[\"Y_test\"], Yhat_test))\n",
    "    print(\"Precision: \", precision_score(Yhat_test, data[\"Y_test\"]))\n",
    "    print(\"Recall: \", recall_score(Yhat_test, data[\"Y_test\"]))\n",
    "    print(\"F1Score: \", f1_score(Yhat_test, data[\"Y_test\"]))\n",
    "    print(\"-------------------------------------------------\")\n",
    "    print(\"Naive Classifier Test accuracy\", accuracy(data[\"Y_test\"], Yhat_test_naive))\n",
    "    print(\"Precision: \", precision_score(Yhat_test_naive, data[\"Y_test\"]))\n",
    "    print(\"Recall: \", recall_score(Yhat_test_naive, data[\"Y_test\"]))\n",
    "    print(\"F1Score: \", f1_score(Yhat_test_naive, data[\"Y_test\"]))\n",
    "    print(\"Logistic Regression weights\", {feature_names[i]: round(best_model.theta[i], 2) for i in range(len(feature_names)-1)})\n",
    "\n",
    "run_logistic_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f3b7c0",
   "metadata": {},
   "source": [
    "Neural Net model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84390a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_neuralnet_model():\n",
    "    \"\"\"\n",
    "    Fits logistic linear regression on an aggregated and cleaned building genome dataset\n",
    "    Prints accuracy results\n",
    "    \"\"\"\n",
    "\n",
    "    ##############################################\n",
    "    ### Best Neural Net Model ###\n",
    "    ##############################################\n",
    "    model_base = MLPClassifier(batch_size=10, max_iter=2000, hidden_layer_sizes=(512,))\n",
    "    model_base.fit(data[\"Xmat_train\"], data[\"Y_train\"])\n",
    "   \n",
    "    Yhat_train_base = model_base.predict(data[\"Xmat_train\"])\n",
    "    Yhat_val_base = model_base.predict(data[\"Xmat_val\"])\n",
    "    \n",
    "    ## ACCURACY ##\n",
    "    accuracy_base_val = accuracy(data[\"Y_val\"], Yhat_val_base)\n",
    "    accuracy_base_train = accuracy(data[\"Y_train\"], Yhat_train_base)\n",
    "\n",
    "    print(\"\\nResults for base model:\\n\" + \"-\"*4)\n",
    "    \n",
    "    ## PRECISION, RECALL, F1 ##    \n",
    "    precision_base_val = precision_score(Yhat_val_base, data[\"Y_val\"])\n",
    "    recall_base_val = recall_score(Yhat_val_base, data[\"Y_val\"])\n",
    "    f1_base_val = f1_score(Yhat_val_base, data[\"Y_val\"])\n",
    "    \n",
    "    precision_base_train = precision_score(Yhat_train_base, data[\"Y_train\"])\n",
    "    recall_base_train = recall_score(Yhat_train_base, data[\"Y_train\"])\n",
    "    f1_base_train = f1_score(Yhat_train_base, data[\"Y_train\"])\n",
    "    \n",
    "    print(\"Validation accuracy: \", accuracy_base_val, \"precision : \", precision_base_val, \" recall: \", recall_base_val, \" F1 score: \", f1_base_val)\n",
    "    print(\"Training accuracy: \", accuracy_base_train, \"precision : \", precision_base_train, \" recall: \", recall_base_train, \" F1 score: \", f1_base_train)\n",
    "    print(\"\\n------------------------\")\n",
    "    \n",
    "    \n",
    "    # choose best model\n",
    "    best_model = model_base\n",
    "    Yhat_test = best_model.predict(data[\"Xmat_test\"])\n",
    "    print(\"Test accuracy\", accuracy(data[\"Y_test\"], Yhat_test))\n",
    "    print(\"Test precision : \", precision_score(Yhat_test, data[\"Y_test\"]))\n",
    "    print(\"Test recall: \", recall_score(Yhat_test, data[\"Y_test\"]), \" F1 score: \", f1_score(Yhat_test, data[\"Y_test\"]))\n",
    "run_neuralnet_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aba1f7d",
   "metadata": {},
   "source": [
    "Run all models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330175a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_ablation_model():\n",
    "    model_base = MLPClassifier(batch_size=10, max_iter=2000, hidden_layer_sizes=(512,))\n",
    "    model_base.fit(ablation_data[\"Xmat_train\"], ablation_data[\"Y_train\"])\n",
    "   \n",
    "    Yhat_train_base = model_base.predict(ablation_data[\"Xmat_train\"])\n",
    "    Yhat_val_base = model_base.predict(ablation_data[\"Xmat_val\"])\n",
    "    \n",
    "    ## ACCURACY ##\n",
    "    accuracy_base_val = accuracy(ablation_data[\"Y_val\"], Yhat_val_base)\n",
    "    accuracy_base_train = accuracy(ablation_data[\"Y_train\"], Yhat_train_base)\n",
    "\n",
    "    print(\"\\nResults for ablation model:\\n\" + \"-\"*4)\n",
    "    \n",
    "    ## PRECISION, RECALL, F1 ##    \n",
    "    precision_base_val = precision_score(Yhat_val_base, ablation_data[\"Y_val\"])\n",
    "    recall_base_val = recall_score(Yhat_val_base, ablation_data[\"Y_val\"])\n",
    "    f1_base_val = f1_score(Yhat_val_base, ablation_data[\"Y_val\"])\n",
    "    \n",
    "    precision_base_train = precision_score(Yhat_train_base, ablation_data[\"Y_train\"])\n",
    "    recall_base_train = recall_score(Yhat_train_base, ablation_data[\"Y_train\"])\n",
    "    f1_base_train = f1_score(Yhat_train_base, ablation_data[\"Y_train\"])\n",
    "    \n",
    "    print(\"Validation accuracy: \", accuracy_base_val, \"precision : \", precision_base_val, \" recall: \", recall_base_val, \" F1 score: \", f1_base_val)\n",
    "    print(\"Training accuracy: \", accuracy_base_train, \"precision : \", precision_base_train, \" recall: \", recall_base_train, \" F1 score: \", f1_base_train)\n",
    "    print(\"\\n------------------------\")\n",
    "    \n",
    "    # choose best model\n",
    "    best_model = model_base\n",
    "    Yhat_test = best_model.predict(ablation_data[\"Xmat_test\"])\n",
    "    print(\"Test accuracy\", accuracy(ablation_data[\"Y_test\"], Yhat_test))\n",
    "    print(\"Test precision : \", precision_score(Yhat_test, ablation_data[\"Y_test\"]), \" recall: \", recall_score(Yhat_test, ablation_data[\"Y_test\"]), \" F1 score: \", f1_score(Yhat_test, ablation_data[\"Y_test\"]))\n",
    "    \n",
    "run_ablation_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
